{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression #C is regularization param\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import stats\n",
    "from sklearn import discriminant_analysis\n",
    "from sklearn import naive_bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data and Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection working!\n"
     ]
    }
   ],
   "source": [
    "from ticket_prediction_data import Ticket_PredictionData\n",
    "\n",
    "tixO = Ticket_PredictionData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying for main table\n",
      "Got main table\n",
      "Simplifying venues\n",
      "Venues simplified\n",
      "Simplifying events\n",
      "Events simplified\n",
      "Simplifying zones\n",
      "Zones simplified\n",
      "Querying for performers\n",
      "Dummying performers\n",
      "Performers dummied\n",
      "Concatenating dummied performers\n",
      "Performers concatanated\n",
      "Starting final cleanup\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = tixO.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 vs 1 counts:      81386,       9229\n",
      "0 vs 1 percentages:      0.898,      0.102\n"
     ]
    }
   ],
   "source": [
    "print('0 vs 1 counts: %10d, %10d' %(np.sum(y_train==0), np.sum(y_train==1))) #\n",
    "print('0 vs 1 percentages: %10.3f, %10.3f' %(np.sum(y_train==0) / y_train.shape[0], np.sum(y_train==1) / y_train.shape[0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Minority class situation!  Will need to address throughout model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression w/o Imbalanced Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[81145   241]\n",
      " [ 8945   284]]\n",
      "AUC 0.790\n",
      "Accuracy: 0.899\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "\n",
    "logistic = LogisticRegression(C=1e5)  # turning off the Ridge regularization\n",
    "\n",
    "logistic.fit(X_train, y_train)\n",
    "logistic_pred = logistic.predict(X_train)\n",
    "logistic_proba = logistic.predict_proba(X_train)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_train, logistic_pred)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_train, logistic_proba[:,1]))) \n",
    "print('Accuracy: %.3f' %(logistic.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[30795   197]\n",
      " [ 3613   173]]\n",
      "AUC 0.707\n",
      "Accuracy: 0.890\n"
     ]
    }
   ],
   "source": [
    "#Holdout\n",
    "\n",
    "logistic_predT = logistic.predict(X_test)\n",
    "logistic_probaT = logistic.predict_proba(X_test)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, logistic_predT)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_test, logistic_probaT[:,1]))) \n",
    "print('Accuracy: %.3f' %(logistic.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Bayesian Rule Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 31743 instances classified into Y=1 (listing not available next day)\n",
      "confusion_matrix:\n",
      " [[56611 24775]\n",
      " [ 2261  6968]]\n",
      "AUC 0.725\n",
      "Accuracy: 0.702\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "\n",
    "print('There are %d instances classified into Y=1 (listing not available next day)' %(np.sum(logistic_proba[:,1]>9229/90615)))\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_train, logistic_proba[:,1]>9229/90615)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_train, logistic_proba[:,1]>9229/90615))) \n",
    "tn, fp, fn, tp = confusion_matrix(y_train, logistic_proba[:,1]>9229/90615).ravel()\n",
    "print('Accuracy: %.3f' %((tn + tp) / (tn + tp + fn + fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11670 instances classified into Y=1 (listing not available next day)\n",
      "confusion_matrix:\n",
      " [[21633  9359]\n",
      " [ 1475  2311]]\n",
      "AUC 0.654\n",
      "Accuracy: 0.688\n"
     ]
    }
   ],
   "source": [
    "#Holdout\n",
    "\n",
    "print('There are %d instances classified into Y=1 (listing not available next day)' %(np.sum(logistic_probaT[:,1]>9229/90615)))\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, logistic_probaT[:,1]>9229/90615)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_test, logistic_probaT[:,1]>9229/90615))) \n",
    "tnT, fpT, fnT, tpT = confusion_matrix(y_test, logistic_probaT[:,1]>9229/90615).ravel()\n",
    "print('Accuracy: %.3f' %((tnT + tpT) / (tnT + tpT + fnT + fpT)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Many more classified into minority class at expense of substantial misclassification to majority class.  Let's try lowering decision boundary even further (.075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 39872 instances classified into Y=1 (listing not available next day)\n",
      "confusion_matrix:\n",
      " [[49125 32261]\n",
      " [ 1618  7611]]\n",
      "AUC 0.714\n",
      "Accuracy: 0.626\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "\n",
    "print('There are %d instances classified into Y=1 (listing not available next day)' %(np.sum(logistic_proba[:,1]>.075)))\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_train, logistic_proba[:,1]>.075)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_train, logistic_proba[:,1]>.075))) \n",
    "tn, fp, fn, tp = confusion_matrix(y_train, logistic_proba[:,1]>.075).ravel()\n",
    "print('Accuracy: %.3f' %((tn + tp) / (tn + tp + fn + fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14953 instances classified into Y=1 (listing not available next day)\n",
      "confusion_matrix:\n",
      " [[18657 12335]\n",
      " [ 1168  2618]]\n",
      "AUC 0.647\n",
      "Accuracy: 0.612\n"
     ]
    }
   ],
   "source": [
    "#Holdout\n",
    "\n",
    "print('There are %d instances classified into Y=1 (listing not available next day)' %(np.sum(logistic_probaT[:,1]>.075)))\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, logistic_probaT[:,1]>.075)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_test, logistic_probaT[:,1]>.075))) \n",
    "tnT, fpT, fnT, tpT = confusion_matrix(y_test, logistic_probaT[:,1]>.075).ravel()\n",
    "print('Accuracy: %.3f' %((tnT + tpT) / (tnT + tpT + fnT + fpT)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We correctly predict ticket listings as being UNAVAILABLE the following day 72% of the time, but only correctly predict tickets being AVAILABLE the following day 58% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Balanced Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[56657 24729]\n",
      " [ 2097  7132]]\n",
      "AUC 0.794\n",
      "Accuracy: 0.704\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "logBal = LogisticRegression(C=1e5, class_weight = 'balanced')  #balanced class weight, ridge regularization turned off\n",
    "\n",
    "logBal.fit(X_train, y_train)\n",
    "logBal_pred = logBal.predict(X_train)\n",
    "logBal_proba = logBal.predict_proba(X_train)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_train, logBal_pred)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_train, logBal_proba[:,1]))) \n",
    "print('Accuracy: %.3f' %(logBal.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[21461  9531]\n",
      " [ 1314  2472]]\n",
      "AUC 0.713\n",
      "Accuracy: 0.688\n"
     ]
    }
   ],
   "source": [
    "#Holdout\n",
    "logBal_predT = logBal.predict(X_test)\n",
    "logBal_probaT = logBal.predict_proba(X_test)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, logBal_predT)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_test, logBal_probaT[:,1]))) \n",
    "print('Accuracy: %.3f' %(logBal.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6923722250903459"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21458 / (21458 + 9534)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We correctly predict ticket listings as being UNAVAILABLE the following day 65% of the time, but only correctly predict tickets being AVAILABLE the following day 69% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Lasso Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[56698 24688]\n",
      " [ 2090  7139]]\n",
      "AUC 0.794\n",
      "Accuracy: 0.704\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "logBalLasso = LogisticRegression(class_weight = 'balanced', penalty = 'l1')  #balanced class weight, Lasso regularization\n",
    "\n",
    "logBalLasso.fit(X_train, y_train)\n",
    "logBalLasso_pred = logBalLasso.predict(X_train)\n",
    "logBalLasso_proba = logBalLasso.predict_proba(X_train)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_train, logBalLasso_pred)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_train, logBalLasso_proba[:,1]))) \n",
    "print('Accuracy: %.3f' %(logBalLasso.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[21487  9505]\n",
      " [ 1322  2464]]\n",
      "AUC 0.711\n",
      "Accuracy: 0.689\n"
     ]
    }
   ],
   "source": [
    "#Holdout\n",
    "logBalLasso_predT = logBalLasso.predict(X_test)\n",
    "logBalLasso_probaT = logBalLasso.predict_proba(X_test)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, logBalLasso_predT)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_test, logBalLasso_probaT[:,1]))) \n",
    "print('Accuracy: %.3f' %(logBalLasso.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Ridge Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[56541 24845]\n",
      " [ 2105  7124]]\n",
      "AUC 0.793\n",
      "Accuracy: 0.703\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "logBalRidge = LogisticRegression(class_weight = 'balanced')  #balanced class weight, Ridge regularization defaults\n",
    "\n",
    "logBalRidge.fit(X_train, y_train)\n",
    "logBalRidge_pred = logBalRidge.predict(X_train)\n",
    "logBalRidge_proba = logBalRidge.predict_proba(X_train)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_train, logBalRidge_pred)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_train, logBalRidge_proba[:,1]))) \n",
    "print('Accuracy: %.3f' %(logBalRidge.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[21520  9472]\n",
      " [ 1323  2463]]\n",
      "AUC 0.716\n",
      "Accuracy: 0.690\n"
     ]
    }
   ],
   "source": [
    "#Holdout\n",
    "logBalRidge_predT = logBalRidge.predict(X_test)\n",
    "logBalRidge_probaT = logBalRidge.predict_proba(X_test)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, logBalRidge_predT)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_test, logBalRidge_probaT[:,1]))) \n",
    "print('Accuracy: %.3f' %(logBalRidge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge with Unbalanced Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[81152   234]\n",
      " [ 9032   197]]\n",
      "AUC 0.790\n",
      "Accuracy: 0.898\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "logRidge = LogisticRegression()  #balanced class weight, Ridge regularization defaults\n",
    "\n",
    "logRidge.fit(X_train, y_train)\n",
    "logRidge_pred = logRidge.predict(X_train)\n",
    "logRidge_proba = logRidge.predict_proba(X_train)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_train, logRidge_pred)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_train, logRidge_proba[:,1]))) \n",
    "print('Accuracy: %.3f' %(logRidge.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[30804   188]\n",
      " [ 3612   174]]\n",
      "AUC 0.709\n",
      "Accuracy: 0.891\n"
     ]
    }
   ],
   "source": [
    "#Holdout\n",
    "logRidge_predT = logRidge.predict(X_test)\n",
    "logRidge_probaT = logRidge.predict_proba(X_test)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, logRidge_predT)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_test, logRidge_probaT[:,1]))) \n",
    "print('Accuracy: %.3f' %(logRidge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso with Unbalanced Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[81174   212]\n",
      " [ 8992   237]]\n",
      "AUC 0.792\n",
      "Accuracy: 0.898\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "logLasso = LogisticRegression(penalty = 'l1')  #balanced class weight, Lasso regularization\n",
    "\n",
    "logLasso.fit(X_train, y_train)\n",
    "logLasso_pred = logLasso.predict(X_train)\n",
    "logLasso_proba = logLasso.predict_proba(X_train)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_train, logLasso_pred)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_train, logLasso_proba[:,1]))) \n",
    "print('Accuracy: %.3f' %(logLasso.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[30794   198]\n",
      " [ 3612   174]]\n",
      "AUC 0.704\n",
      "Accuracy: 0.890\n"
     ]
    }
   ],
   "source": [
    "#Holdout\n",
    "logLasso_predT = logLasso.predict(X_test)\n",
    "logLasso_probaT = logLasso.predict_proba(X_test)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, logLasso_predT)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_test, logLasso_probaT[:,1]))) \n",
    "print('Accuracy: %.3f' %(logLasso.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (linear kernel, class_weight = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[81386     0]\n",
      " [ 9229     0]]\n",
      "AUC 0.622\n",
      "Accuracy: 0.898\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "\n",
    "svm = SVC(kernel = 'linear', class_weight = None, probability = True)\n",
    "\n",
    "svm.fit(X_train.iloc[:500,], y_train[:500])\n",
    "svm_pred = svm.predict(X_train)\n",
    "svm_proba = svm.predict_proba(X_train)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_train, svm_pred)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_train, svm_proba[:,1]))) \n",
    "print('Accuracy: %.3f' %(svm.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix:\n",
      " [[30992     0]\n",
      " [ 3786     0]]\n",
      "AUC 0.585\n",
      "Accuracy: 0.891\n"
     ]
    }
   ],
   "source": [
    "#Holdout\n",
    "\n",
    "svm_predT = svm.predict(X_test)\n",
    "svm_probaT = svm.predict_proba(X_test)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, svm_predT)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_test, svm_probaT[:,1]))) \n",
    "print('Accuracy: %.3f' %(svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Linear SVM with class_weight = None classifies every observation to majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (linear kernel, class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmB = SVC(kernel = 'linear', class_weight = 'balanced', probability = True)\n",
    "\n",
    "svmB.fit(X_train.iloc[:500,], y_train[:500])\n",
    "svm_predB = svmB.predict(X_train)\n",
    "svm_probaB = svmB.predict_proba(X_train)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_train, svm_predB)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_train, svm_probaB[:,1]))) \n",
    "print('Accuracy: %.3f' %(svmB.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Holdout\n",
    "\n",
    "svmB_predT = svmB.predict(X_test)\n",
    "svmB_probaT = svmB.predict_proba(X_test)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, svmB_predT)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_test, svmB_probaT[:,1]))) \n",
    "print('Accuracy: %.3f' %(svmB.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw ROC Curve for balanced vs unbalanced\n",
    "\n",
    "scoreA = svm.decision_function(X_test)\n",
    "scoreB = svmB.decision_function(X_test)\n",
    "\n",
    "A=roc_curve(y_test,scoreA,pos_label=0)\n",
    "B=roc_curve(y_test,scoreB,pos_label=0)\n",
    "\n",
    "plt.plot(A[0],A[1],label='RAW ROC Naive Linear SVM Holdout')\n",
    "plt.plot(B[0],B[1],label='RAW ROC Balanced Linear SVM Holdout')\n",
    "plt.xlim((-0.2,1.1))\n",
    "plt.ylim((-0.1,1.1))\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (radial kernel, class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "\n",
    "svmBR = SVC(kernel = 'rbf', class_weight = 'balanced', probability = True)\n",
    "\n",
    "svmBR.fit(X_train.iloc[:25000,], y_train[:25000])\n",
    "svm_predBR = svmBR.predict(X_train)\n",
    "svm_probaBR = svmBR.predict_proba(X_train)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_train, svm_predBR)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_train, svm_probaBR[:,1]))) \n",
    "print('Accuracy: %.3f' %(svmBR.score(X_train, y_train))) #~20m to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Holdout\n",
    "\n",
    "svmBR_predT = svmBR.predict(X_test)\n",
    "svmBR_probaT = svmBR.predict_proba(X_test)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, svmBR_predT)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_test, svmBR_probaT[:,1]))) \n",
    "print('Accuracy: %.3f' %(svmBR.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreC = svmBR.decision_function(X_test)\n",
    "A=roc_curve(y_test,scoreA,pos_label=1)\n",
    "B=roc_curve(y_test,scoreB,pos_label=1)\n",
    "C=roc_curve(y_test,scoreC,pos_label=1)\n",
    "\n",
    "plt.plot(A[0],A[1],label='ROC Naive Linear SVM Holdout')\n",
    "plt.plot(B[0],B[1],label='ROC Balanced Linear SVM Holdout')\n",
    "plt.plot(C[0],C[1],label='ROC Balanced Radial SVM Holdout')\n",
    "plt.xlim((-0.2,1.1))\n",
    "plt.ylim((-0.1,1.1))\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "\n",
    "LDA = discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "\n",
    "LDA.fit(X_train, y_train)\n",
    "LDA_pred = LDA.predict(X_train)\n",
    "LDA_proba = LDA.predict_proba(X_train)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_train, LDA_pred)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_train, LDA_proba[:,1]))) \n",
    "print('Accuracy: %.3f' %(LDA.score(X_train, y_train))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Holdout\n",
    "\n",
    "LDA_predT = LDA.predict(X_test)\n",
    "LDA_probaT = LDA.predict_proba(X_test)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, LDA_predT)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_test, LDA_probaT[:,1]))) \n",
    "print('Accuracy: %.3f' %(LDA.score(X_test, y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at different cut-off\n",
    "\n",
    "print('There are %d instances classified into Y=1 (listing not available next day)' %(np.sum(LDA_probaT[:,1]>.105)))\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, LDA_probaT[:,1]>.105)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_test, LDA_probaT[:,1]>.105))) \n",
    "LDAtn, LDAfp, LDAfn, LDAtp = confusion_matrix(y_test, LDA_probaT[:,1]>.105).ravel()\n",
    "print('Accuracy: %.3f' %((LDAtn + LDAtp) / (LDAtn + LDAtp + LDAfn + LDAfp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "\n",
    "QDA = discriminant_analysis.QuadraticDiscriminantAnalysis(reg_param = 0.01)\n",
    "\n",
    "QDA.fit(X_train, y_train)\n",
    "QDA_pred = QDA.predict(X_train)\n",
    "QDA_proba = QDA.predict_proba(X_train)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_train, QDA_pred)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_train, QDA_proba[:,1]))) \n",
    "print('Accuracy: %.3f' %(QDA.score(X_train, y_train))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Holdout\n",
    "\n",
    "QDA_predT = QDA.predict(X_test)\n",
    "QDA_probaT = QDA.predict_proba(X_test)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, QDA_predT)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_test, QDA_probaT[:,1]))) \n",
    "print('Accuracy: %.3f' %(QDA.score(X_test, y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "pca.fit(X_train)\n",
    "np.sum(pca.explained_variance_ratio_[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaOp = PCA(n_components = 2)\n",
    "pcaOp.fit(X_train)\n",
    "\n",
    "X_train_PCA = pcaOp.transform(X_train)\n",
    "\n",
    "#Training\n",
    "\n",
    "QDA_pca = discriminant_analysis.QuadraticDiscriminantAnalysis()\n",
    "\n",
    "QDA_pca.fit(X_train_PCA, y_train)\n",
    "QDA_pca_pred = QDA_pca.predict(X_train_PCA)\n",
    "QDA_pca_proba = QDA_pca.predict_proba(X_train_PCA)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_train, QDA_pca_pred)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_train, QDA_pca_proba[:,1]))) \n",
    "print('Accuracy: %.3f' %(QDA_pca.score(X_train_PCA, y_train))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Holdout\n",
    "\n",
    "X_test_PCA = pcaOp.transform(X_test)\n",
    "\n",
    "QDA_predT_pca = QDA_pca.predict(X_test_PCA)\n",
    "QDA_probaT_pca = QDA_pca.predict_proba(X_test_PCA)\n",
    "\n",
    "print('confusion_matrix:\\n', confusion_matrix(y_test, QDA_predT_pca)) \n",
    "print('AUC %.3f' %(roc_auc_score(y_test, QDA_probaT_pca[:,1]))) \n",
    "print('Accuracy: %.3f' %(QDA_pca.score(X_test_PCA, y_test))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout AUC Summary\n",
    "\n",
    "QDA w/ regularization: .728 <br>\n",
    "Logistic w/ Balanced Weight, L2 Penalty: .714 <br>\n",
    "Logistic w/ Balanced Weight, L1 Penalty: .711 <br>\n",
    "Logistic w/ Balanced Class Weight: .709 <br>\n",
    "Logistic: .707 <br>\n",
    "SVM w/ Radial Kernel, Balanced Class Weight : .699 <br>\n",
    "LDA: .686 <br>\n",
    "Logistic w/ Bayesian Decision Boundary: .654 <br>\n",
    "QDA w/ 2 component PCA (99% variance - entirely majority class): .607 <br>\n",
    "SVM w/ Linear Kernel, Balanced Class Weight: .551 <br>\n",
    "SVM: .391 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Score Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L = np.zeros((2,2))\n",
    "#L[1,0] = 1\n",
    "#L[0,1] = 0.1\n",
    "\n",
    "#def LossScore(CHAS,CHAS_proba, L, cut_off):\n",
    "#    return(np.sum((L*confusion_matrix(CHAS, CHAS_proba[:,1]>cut_off)).flatten()))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
